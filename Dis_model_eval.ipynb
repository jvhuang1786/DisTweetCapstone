{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import time\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import gensim\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('DiSmldata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axes = plt.subplots(figsize=(20,7))\n",
    "ax = sns.countplot(x=df[\"label\"], palette=\"OrRd_r\")\n",
    "ax.set(title=\"Distribution of Product Ratings\", \\\n",
    "       xlabel=\"Sentiment\", ylabel=\"Sentiment Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = ENGLISH_STOP_WORDS.union(['disneyland','tokyo','disney', 'im', 'tdrnow','paris','california','amp','disneysea','got',\n",
    "                                         '¬∫c', '¬∫f', '¬∫o¬∫','ùóßùóµùó≤','„Åè„Åæ„ÅÆ„Éó„Éº„Åï„Çì', '„Éá„Ç£„Ç∫„Éã„Éº', '„Éá„Ç£„Ç∫„Éã„Éº„Ç∑„Éº','„Éá„Ç£„Ç∫„Éã„Éº„Éè„É≠„Ç¶„Ç£„Éº„É≥',\n",
    "                                         '„Éá„Ç£„Ç∫„Éã„Éº„É©„É≥„Éâ', '„Éá„Ç£„Ç∫„Éã„ÉºÂ•Ω„Åç„Å®Áπã„Åå„Çä„Åü„ÅÑ', '„Éï„Çß„Çπ„ÉÜ„Ç£„Éê„É´„Ç™„Éñ„Éü„Çπ„ÉÜ„Ç£„Éº„ÇØ', '„Éû„É´„Éû„É≥',\n",
    "                                         '„Öã„Öã„Öã', 'Â†¥ÊâÄ', 'Êõ¥Êñ∞', 'Êúàreleased', 'Êù±‰∫¨„Éá„Ç£„Ç∫„Éã„Éº„Ç∑„Éº', 'Êù±‰∫¨„Éá„Ç£„Ç∫„Éã„Éº„É©„É≥„Éâ', 'Êù±‰∫¨„Éá„Ç£„Ç∫„Éã„Éº„É™„Çæ„Éº„Éà',\n",
    "                                         'È¶ôÊ∏ØËø™Â£´Â∞ºÊ®ÇÂúí', '¬∫¬∫', 'hong', 'kong',\"disneylandresort\", \"disneyland\", \"disneyresort\",\n",
    "                                          \"californiaadventure\",'downtowndisney','disneyanaheim','disneylandanaheim',\n",
    "                                          'disneycalifornia','californiadisney','disneysea', 'disneytokyo', 'disneytokyoresort', \n",
    "                                          'tokyodisney','tokyodisneyresort', 'tokyodisneyland','Êù±‰∫¨„Éá„Ç£„Ç∫„Éã„Éº„É©„É≥„Éâ', '„Éá„Ç£„Ç∫„Éã„Éº„É©„É≥„Éâ',\n",
    "                                          'Êù±‰∫¨„Éá„Ç£„Ç∫„Éã„Éº„Ç∑„Éº', '„Ç∫„Éã„Éº„Ç∑„Éº', 'tdr_now', 'tdr_md','tdr','dca','dl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['hash_count', 'emoji_count','clean_text',\n",
    "                                                        'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']], df['label'],test_size =0.20, random_state = 77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count vectorizer Document term matrix\n",
    "count_vect = CountVectorizer(stop_words = my_stop_words, min_df = 0.005)\n",
    "count_vect_fit = count_vect.fit(X_train['clean_text'])\n",
    "\n",
    "count_train = count_vect_fit.transform(X_train['clean_text'])\n",
    "count_test = count_vect_fit.transform(X_test['clean_text'])\n",
    "\n",
    "X_train_vect = pd.concat([X_train[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(count_train.toarray())], axis=1)\n",
    "X_test_vect = pd.concat([X_test[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(count_test.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70008, 230)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 23522), (1, 23522), (2, 23522), (3, 23522), (4, 23522), (5, 23522)]\n"
     ]
    }
   ],
   "source": [
    "#Balance the Data \n",
    "ros = RandomOverSampler(random_state=77)\n",
    "X_resampled_ros, y_resampled_ros = ros.fit_resample(X_train_vect.values, y_train.values)\n",
    "print(sorted(Counter(y_resampled_ros).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5982), (1, 5982), (2, 5982), (3, 5982), (4, 5982), (5, 5982)]\n"
     ]
    }
   ],
   "source": [
    "X_resampled_ros_test, y_resampled_ros_test = ros.fit_resample(X_test_vect.values, y_test.values)\n",
    "print(sorted(Counter(y_resampled_ros_test).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 12.105 / Predict time: 0.356 ---- Precision: 0.617 / Recall: 0.589 / Accuracy: 0.589\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "#Instantiate our model \n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=1000, n_jobs=-1)\n",
    "\n",
    "#Model Fit \n",
    "start = time.time()\n",
    "rf.fit(X_resampled_ros, y_resampled_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_resampled_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1303768456287617, 'tweet_len'),\n",
       " (0.07807822616226266, 'cap_count'),\n",
       " (0.07010841356118133, 'punc_count'),\n",
       " (0.057022406417206975, 'hash_count'),\n",
       " (0.02898339490109582, 'sadness'),\n",
       " (0.02687734180905905, 'emoji_count'),\n",
       " (0.025203949296349795, 'joy'),\n",
       " (0.023096638219575978, 'fear'),\n",
       " (0.01948154748113576, 'anticipation'),\n",
       " (0.01909843941302194, 'anger'),\n",
       " (0.017722890983914507, 'trust'),\n",
       " (0.014656758600497581, 'disgust'),\n",
       " (0.012118719656079035, 'surprise'),\n",
       " (0.011720533443747589, 29),\n",
       " (0.010807713899821336, 90),\n",
       " (0.0077703141307843265, 197),\n",
       " (0.0071537028588388495, 31),\n",
       " (0.006016422446220515, 69),\n",
       " (0.005973557340930049, 64),\n",
       " (0.005850698696712951, 181)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest tells our Feature Importances\n",
    "importances = rf.feature_importances_\n",
    "(sorted(zip(importances, X_train_vect.columns), reverse=True))[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 3.642 / Predict time: 0.07 ---- Precision: 0.518 / Recall: 0.514 / Accuracy: 0.514\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Bayes\n",
    "\n",
    "#Instantiate our model \n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "#Train our Model \n",
    "start = time.time()\n",
    "nb_clf.fit(X_resampled_ros, y_resampled_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = nb_clf.predict(X_resampled_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), \n",
    "    round(recall, 3), round((y_pred==y_resampled_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 7.365 / Predict time: 0.045 ---- Precision: 0.459 / Recall: 0.444 / Accuracy: 0.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "\n",
    "#Instantiate our model\n",
    "lr = LogisticRegression(max_iter = 100, solver = 'lbfgs')\n",
    "\n",
    "#Train our Model\n",
    "start = time.time()\n",
    "lr.fit(X_resampled_ros, y_resampled_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = lr.predict(X_resampled_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), \n",
    "    round((y_pred==y_resampled_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF vector DTM\n",
    "tfidf_vect = TfidfVectorizer(stop_words = my_stop_words, min_df = 0.005)\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['clean_text'])\n",
    "\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['clean_text'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['clean_text'])\n",
    "\n",
    "X_train_vect_tf = pd.concat([X_train[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "X_test_vect_tf = pd.concat([X_test[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_test.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70008, 230)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 23522), (1, 23522), (2, 23522), (3, 23522), (4, 23522), (5, 23522)]\n"
     ]
    }
   ],
   "source": [
    "#Balance the Data \n",
    "ros = RandomOverSampler(random_state=77) \n",
    "X_resampled_ros_tf, y_resampled_ros_tf = ros.fit_resample(X_train_vect_tf.values, y_train.values)\n",
    "print(sorted(Counter(y_resampled_ros_tf).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5982), (1, 5982), (2, 5982), (3, 5982), (4, 5982), (5, 5982)]\n"
     ]
    }
   ],
   "source": [
    "X_resampled_ros_test_tf, y_resampled_ros_test_tf = ros.fit_resample(X_test_vect_tf.values, y_test.values)\n",
    "print(sorted(Counter(y_resampled_ros_test_tf).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 12.138 / Predict time: 0.349 ---- Precision: 0.614 / Recall: 0.584 / Accuracy: 0.584\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "#Instantiate our model \n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=1000, n_jobs=-1)\n",
    "\n",
    "#Model Fit \n",
    "start = time.time()\n",
    "rf.fit(X_resampled_ros_tf, y_resampled_ros_tf)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_resampled_ros_test_tf)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test_tf, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_ros_test_tf).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.12106733725450405, 'tweet_len'),\n",
       " (0.07098867227488843, 'cap_count'),\n",
       " (0.06614191209394779, 'punc_count'),\n",
       " (0.05582949659414724, 'hash_count'),\n",
       " (0.027689268039805655, 'sadness'),\n",
       " (0.024820731788330032, 'fear'),\n",
       " (0.024271540740605047, 'emoji_count'),\n",
       " (0.023564576692525548, 'joy'),\n",
       " (0.0169774729545499, 'anticipation'),\n",
       " (0.01645790531903967, 'trust'),\n",
       " (0.015490519161953504, 'anger'),\n",
       " (0.01510264703412933, 'disgust'),\n",
       " (0.012640094971237843, 90),\n",
       " (0.012188790678675869, 29),\n",
       " (0.011220898542607742, 'surprise'),\n",
       " (0.008626177314886676, 197),\n",
       " (0.00830021294399549, 181),\n",
       " (0.008278631893969943, 31),\n",
       " (0.006798141052192894, 64),\n",
       " (0.006744256438246525, 69)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest tells our Feature Importances\n",
    "importances = rf.feature_importances_\n",
    "(sorted(zip(importances, X_train_vect_tf.columns), reverse=True))[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 0.11 / Predict time: 0.016 ---- Precision: 0.499 / Recall: 0.495 / Accuracy: 0.495\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Bayes\n",
    "\n",
    "#Instantiate our model \n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "#Train our Model \n",
    "start = time.time()\n",
    "nb_clf.fit(X_resampled_ros_tf, y_resampled_ros_tf)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = nb_clf.predict(X_resampled_ros_test_tf)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test_tf, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_ros_test_tf).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 7.746 / Predict time: 0.012 ---- Precision: 0.438 / Recall: 0.425 / Accuracy: 0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "\n",
    "#Instantiate our model\n",
    "lr = LogisticRegression(max_iter = 100, solver = 'lbfgs')\n",
    "\n",
    "#Train our Model\n",
    "start = time.time()\n",
    "lr.fit(X_resampled_ros_tf, y_resampled_ros_tf)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = lr.predict(X_resampled_ros_test_tf)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test_tf, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_ros_test_tf).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_tweet = df.clean_text.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12701458, 17727920)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v = gensim.models.Word2Vec(\n",
    "            tokenized_tweet,\n",
    "            size=230, # desired no. of features/independent variables \n",
    "            window=3, # context window size\n",
    "            min_count=30,\n",
    "            sg = 1, # 1 for skip-gram model\n",
    "            seed = 77)\n",
    "\n",
    "model_w2v.train(tokenized_tweet, total_examples= len(df['clean_text']), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('disneysea', 0.5430849194526672),\n",
       " ('disneylandtokyo', 0.46373534202575684),\n",
       " ('Êù±‰∫¨„Éá„Ç£„Ç∫„Éã„Éº„É™„Çæ„Éº„Éà', 0.39844822883605957),\n",
       " ('sea', 0.3980148136615753),\n",
       " ('steamer', 0.39004385471343994),\n",
       " ('tokyodisney', 0.37289878726005554),\n",
       " ('tue', 0.3697461485862732),\n",
       " ('port', 0.3695187270641327),\n",
       " ('transit', 0.36897897720336914),\n",
       " ('chiba', 0.368430495262146)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(\"tokyo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bff', 0.39314982295036316),\n",
       " ('blast', 0.3678790330886841),\n",
       " ('sundayfunday', 0.32133573293685913),\n",
       " ('vote', 0.3198425769805908),\n",
       " ('memories', 0.3136768043041229),\n",
       " ('awesome', 0.30930376052856445),\n",
       " ('enjoyed', 0.3059080243110657),\n",
       " ('enjoying', 0.30518752336502075),\n",
       " ('cosplay', 0.3031541705131531),\n",
       " ('spooktacular', 0.3029031455516815)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(\"fun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('disneyjobs', 0.3763093650341034),\n",
       " ('annualpassholder', 0.34122025966644287),\n",
       " ('themeparks', 0.3221602737903595),\n",
       " ('losangeles', 0.3192991614341736),\n",
       " ('harbor', 0.31923311948776245),\n",
       " ('socal', 0.31771254539489746),\n",
       " ('gaydays', 0.3149857819080353),\n",
       " ('district', 0.31309419870376587),\n",
       " ('goofys', 0.3083474636077881),\n",
       " ('california', 0.3052617311477661)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(\"anaheim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bullshit', 0.40894144773483276),\n",
       " ('fucked', 0.40067780017852783),\n",
       " ('rage', 0.36938905715942383),\n",
       " ('human', 0.36319437623023987),\n",
       " ('losing', 0.3567168712615967),\n",
       " ('ball', 0.35210132598876953),\n",
       " ('lack', 0.3520182967185974),\n",
       " ('brain', 0.3508557379245758),\n",
       " ('confused', 0.3503156900405884),\n",
       " ('umbrella', 0.3469950556755066)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(\"boring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('disneyfan', 0.519191563129425),\n",
       " ('disneyfans', 0.4954191744327545),\n",
       " ('disneyig', 0.4932956397533417),\n",
       " ('disneyaddict', 0.49034011363983154),\n",
       " ('disneyland', 0.4743539094924927),\n",
       " ('disneymagic', 0.4639242887496948),\n",
       " ('disneylove', 0.46227356791496277),\n",
       " ('disneystyle', 0.44713208079338074),\n",
       " ('instadisney', 0.44141948223114014),\n",
       " ('disneyparks', 0.43604254722595215)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(\"disney\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not in vocabulary\n",
    "                         \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_tweet), 230))\n",
    "\n",
    "for i in range(len(tokenized_tweet)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 230)\n",
    "\n",
    "wordvec_df = pd.concat([df[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(wordvec_arrays)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_count</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>...</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045284</td>\n",
       "      <td>-0.079552</td>\n",
       "      <td>0.093554</td>\n",
       "      <td>0.043960</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>0.080055</td>\n",
       "      <td>0.072261</td>\n",
       "      <td>-0.102041</td>\n",
       "      <td>-0.080967</td>\n",
       "      <td>0.049143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117812</td>\n",
       "      <td>0.019281</td>\n",
       "      <td>-0.072755</td>\n",
       "      <td>-0.102343</td>\n",
       "      <td>0.205131</td>\n",
       "      <td>0.159179</td>\n",
       "      <td>-0.055840</td>\n",
       "      <td>-0.087664</td>\n",
       "      <td>-0.051933</td>\n",
       "      <td>0.072010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088095</td>\n",
       "      <td>0.056327</td>\n",
       "      <td>-0.076466</td>\n",
       "      <td>0.027169</td>\n",
       "      <td>-0.124262</td>\n",
       "      <td>0.073991</td>\n",
       "      <td>0.100744</td>\n",
       "      <td>-0.075328</td>\n",
       "      <td>-0.201656</td>\n",
       "      <td>0.097621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251371</td>\n",
       "      <td>-0.048714</td>\n",
       "      <td>0.191657</td>\n",
       "      <td>0.104738</td>\n",
       "      <td>0.066017</td>\n",
       "      <td>0.154219</td>\n",
       "      <td>0.200543</td>\n",
       "      <td>-0.210700</td>\n",
       "      <td>-0.070858</td>\n",
       "      <td>-0.040129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067614</td>\n",
       "      <td>0.054041</td>\n",
       "      <td>-0.019578</td>\n",
       "      <td>-0.034596</td>\n",
       "      <td>0.050744</td>\n",
       "      <td>0.033172</td>\n",
       "      <td>0.063536</td>\n",
       "      <td>-0.074226</td>\n",
       "      <td>-0.051851</td>\n",
       "      <td>0.057051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87505</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219816</td>\n",
       "      <td>-0.169808</td>\n",
       "      <td>-0.157795</td>\n",
       "      <td>-0.054618</td>\n",
       "      <td>-0.047840</td>\n",
       "      <td>0.293229</td>\n",
       "      <td>-0.039973</td>\n",
       "      <td>0.030857</td>\n",
       "      <td>-0.039618</td>\n",
       "      <td>-0.102461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87506</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272423</td>\n",
       "      <td>-0.363468</td>\n",
       "      <td>-0.109325</td>\n",
       "      <td>0.039305</td>\n",
       "      <td>-0.080120</td>\n",
       "      <td>0.232073</td>\n",
       "      <td>-0.017409</td>\n",
       "      <td>0.204312</td>\n",
       "      <td>-0.154984</td>\n",
       "      <td>0.541024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87507</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055245</td>\n",
       "      <td>-0.048646</td>\n",
       "      <td>-0.186082</td>\n",
       "      <td>-0.032606</td>\n",
       "      <td>0.008366</td>\n",
       "      <td>-0.078292</td>\n",
       "      <td>0.032201</td>\n",
       "      <td>-0.106753</td>\n",
       "      <td>0.251502</td>\n",
       "      <td>-0.124243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87508</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101566</td>\n",
       "      <td>-0.135424</td>\n",
       "      <td>-0.203906</td>\n",
       "      <td>-0.071573</td>\n",
       "      <td>-0.062181</td>\n",
       "      <td>0.030170</td>\n",
       "      <td>0.011955</td>\n",
       "      <td>0.049640</td>\n",
       "      <td>-0.100044</td>\n",
       "      <td>0.016892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87509</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067674</td>\n",
       "      <td>0.047803</td>\n",
       "      <td>0.032477</td>\n",
       "      <td>0.045573</td>\n",
       "      <td>-0.013395</td>\n",
       "      <td>0.019374</td>\n",
       "      <td>0.198928</td>\n",
       "      <td>-0.117779</td>\n",
       "      <td>-0.095353</td>\n",
       "      <td>0.025168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87510 rows √ó 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hash_count  emoji_count  anger  anticipation  disgust  fear  joy  \\\n",
       "0               1            0      0             0        0     0    0   \n",
       "1               1            0      0             1        0     0    0   \n",
       "2               0            0      0             0        0     0    0   \n",
       "3               1            0      0             0        0     0    0   \n",
       "4               0            0      0             1        0     1    1   \n",
       "...           ...          ...    ...           ...      ...   ...  ...   \n",
       "87505           3            0      0             0        0     0    0   \n",
       "87506           1            1      1             2        0     1    4   \n",
       "87507           0            0      0             0        0     0    0   \n",
       "87508           0            0      0             1        0     0    1   \n",
       "87509           0            2      1             0        1     0    0   \n",
       "\n",
       "       sadness  surprise  trust  ...       220       221       222       223  \\\n",
       "0            0         0      0  ... -0.045284 -0.079552  0.093554  0.043960   \n",
       "1            0         0      0  ... -0.117812  0.019281 -0.072755 -0.102343   \n",
       "2            0         0      0  ...  0.088095  0.056327 -0.076466  0.027169   \n",
       "3            0         0      0  ... -0.251371 -0.048714  0.191657  0.104738   \n",
       "4            0         0      1  ...  0.067614  0.054041 -0.019578 -0.034596   \n",
       "...        ...       ...    ...  ...       ...       ...       ...       ...   \n",
       "87505        0         0      0  ... -0.219816 -0.169808 -0.157795 -0.054618   \n",
       "87506        1         4      4  ... -0.272423 -0.363468 -0.109325  0.039305   \n",
       "87507        0         0      0  ...  0.055245 -0.048646 -0.186082 -0.032606   \n",
       "87508        0         0      0  ... -0.101566 -0.135424 -0.203906 -0.071573   \n",
       "87509        0         0      0  ... -0.067674  0.047803  0.032477  0.045573   \n",
       "\n",
       "            224       225       226       227       228       229  \n",
       "0      0.028761  0.080055  0.072261 -0.102041 -0.080967  0.049143  \n",
       "1      0.205131  0.159179 -0.055840 -0.087664 -0.051933  0.072010  \n",
       "2     -0.124262  0.073991  0.100744 -0.075328 -0.201656  0.097621  \n",
       "3      0.066017  0.154219  0.200543 -0.210700 -0.070858 -0.040129  \n",
       "4      0.050744  0.033172  0.063536 -0.074226 -0.051851  0.057051  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "87505 -0.047840  0.293229 -0.039973  0.030857 -0.039618 -0.102461  \n",
       "87506 -0.080120  0.232073 -0.017409  0.204312 -0.154984  0.541024  \n",
       "87507  0.008366 -0.078292  0.032201 -0.106753  0.251502 -0.124243  \n",
       "87508 -0.062181  0.030170  0.011955  0.049640 -0.100044  0.016892  \n",
       "87509 -0.013395  0.019374  0.198928 -0.117779 -0.095353  0.025168  \n",
       "\n",
       "[87510 rows x 243 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and validation set\n",
    "xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(wordvec_df, df['label'],  \n",
    "                                                          random_state=77, \n",
    "                                                          test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 23522), (1, 23522), (2, 23522), (3, 23522), (4, 23522), (5, 23522)]\n"
     ]
    }
   ],
   "source": [
    "#Balance the Data \n",
    "ros = RandomOverSampler(random_state=77) \n",
    "X_resampled_w2vec, y_resampled_w2vec = ros.fit_resample(xtrain_bow.values, ytrain.values)\n",
    "print(sorted(Counter(y_resampled_w2vec).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5982), (1, 5982), (2, 5982), (3, 5982), (4, 5982), (5, 5982)]\n"
     ]
    }
   ],
   "source": [
    "X_resampled_w2vec_t, y_resampled_w2vec_t = ros.fit_resample(xvalid_bow.values, yvalid.values)\n",
    "print(sorted(Counter(y_resampled_w2vec_t).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 20.571 / Predict time: 0.236 ---- Precision: 0.417 / Recall: 0.364 / Accuracy: 0.364\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "#Instantiate our model \n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=1000, n_jobs=-1)\n",
    "\n",
    "#Model Fit \n",
    "start = time.time()\n",
    "rf.fit(X_resampled_w2vec, y_resampled_w2vec)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_resampled_w2vec_t)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_w2vec_t, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_w2vec_t).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0298787766668389, 'hash_count'),\n",
       " (0.02638732207990354, 'tweet_len'),\n",
       " (0.018613391096563698, 'joy'),\n",
       " (0.018224906714123034, 'sadness'),\n",
       " (0.016765954856981746, 'fear'),\n",
       " (0.014607287266884952, 'punc_count'),\n",
       " (0.012607334110587693, 'cap_count'),\n",
       " (0.00934111906917256, 'anger'),\n",
       " (0.00821606744911832, 'disgust'),\n",
       " (0.007404822906164451, 'anticipation'),\n",
       " (0.007172041882647434, 'trust'),\n",
       " (0.0040809334133001555, 'surprise'),\n",
       " (0.0039594486196118965, 'emoji_count'),\n",
       " (0.003867090805706925, 76),\n",
       " (0.003809663756012949, 159),\n",
       " (0.0037864113486686685, 101),\n",
       " (0.003784440279148222, 123),\n",
       " (0.0037709644625289664, 189),\n",
       " (0.003757757808505309, 221),\n",
       " (0.0037573237271764266, 133)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest tells our Feature Importances\n",
    "importances = rf.feature_importances_\n",
    "(sorted(zip(importances, xtrain_bow.columns), reverse=True))[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 5.932 / Predict time: 47.942 ---- Precision: 0.333 / Recall: 0.329 / Accuracy: 0.329\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Instantiate our model \n",
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "\n",
    "#Model Fit \n",
    "start = time.time()\n",
    "knn.fit(X_resampled_w2vec, y_resampled_w2vec)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = knn.predict(X_resampled_w2vec_t)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_w2vec_t, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_w2vec_t).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 0.655 / Predict time: 0.009 ---- Precision: 0.399 / Recall: 0.391 / Accuracy: 0.391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "\n",
    "#Instantiate our model\n",
    "lr = LogisticRegression(max_iter = 10, solver = 'lbfgs')\n",
    "\n",
    "#Train our Model\n",
    "start = time.time()\n",
    "lr.fit(X_train_scaled, y_resampled_w2vec)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_w2vec_t, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_w2vec_t).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
