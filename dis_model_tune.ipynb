{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import time\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameter Tuning with Crossvalidation in GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('DiSmldata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_count</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>tweet_len</th>\n",
       "      <th>cap_count</th>\n",
       "      <th>user_follower</th>\n",
       "      <th>user_favorite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>new mickey flower bed going make event photo l...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>193</td>\n",
       "      <td>20</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>thought different yesterday mickey flower bed ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>13</td>\n",
       "      <td>638.0</td>\n",
       "      <td>195775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mickey flower bed renewed tokyo disneyland tod...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mickey flower bed back tdrnow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>72</td>\n",
       "      <td>12</td>\n",
       "      <td>83.0</td>\n",
       "      <td>8334.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>god has face changed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>882.0</td>\n",
       "      <td>41436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87503</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>hurtado help cypress overpower pacifica finish...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>11</td>\n",
       "      <td>572.0</td>\n",
       "      <td>124266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>oct agricultural counsellor attended award cer...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>256</td>\n",
       "      <td>24</td>\n",
       "      <td>82.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>being single move</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>788.0</td>\n",
       "      <td>22525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>time pose hard without laughing disneyland def...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87509</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>who let yall damn cute wtf</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>550.0</td>\n",
       "      <td>15303.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87510 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hash_count  emoji_count  \\\n",
       "0               1            0   \n",
       "2               1            0   \n",
       "5               0            0   \n",
       "17              1            0   \n",
       "19              0            0   \n",
       "...           ...          ...   \n",
       "87503           3            0   \n",
       "87504           1            1   \n",
       "87506           0            0   \n",
       "87508           0            0   \n",
       "87509           0            2   \n",
       "\n",
       "                                              clean_text  label  anger  \\\n",
       "0      new mickey flower bed going make event photo l...      2      0   \n",
       "2      thought different yesterday mickey flower bed ...      1      0   \n",
       "5      mickey flower bed renewed tokyo disneyland tod...      1      0   \n",
       "17                         mickey flower bed back tdrnow      1      0   \n",
       "19                                  god has face changed      1      0   \n",
       "...                                                  ...    ...    ...   \n",
       "87503  hurtado help cypress overpower pacifica finish...      5      0   \n",
       "87504  oct agricultural counsellor attended award cer...      5      1   \n",
       "87506                                  being single move      4      0   \n",
       "87508  time pose hard without laughing disneyland def...      3      0   \n",
       "87509                         who let yall damn cute wtf      4      1   \n",
       "\n",
       "       anticipation  disgust  fear  joy  sadness  surprise  trust  punc_count  \\\n",
       "0                 0        0     0    0        0         0      0           9   \n",
       "2                 1        0     0    0        0         0      0          10   \n",
       "5                 0        0     0    0        0         0      0          12   \n",
       "17                0        0     0    0        0         0      0          10   \n",
       "19                1        0     1    1        0         0      1           0   \n",
       "...             ...      ...   ...  ...      ...       ...    ...         ...   \n",
       "87503             0        0     0    0        0         0      0          11   \n",
       "87504             2        0     1    4        1         4      4           9   \n",
       "87506             0        0     0    0        0         0      0           0   \n",
       "87508             1        0     0    1        0         0      0           2   \n",
       "87509             0        1     0    0        0         0      0           0   \n",
       "\n",
       "       tweet_len  cap_count  user_follower  user_favorite  \n",
       "0            193         20         1214.0          982.0  \n",
       "2            115         13          638.0       195775.0  \n",
       "5            119         16          157.0         4158.0  \n",
       "17            72         12           83.0         8334.0  \n",
       "19            29          3          882.0        41436.0  \n",
       "...          ...        ...            ...            ...  \n",
       "87503        124         11          572.0       124266.0  \n",
       "87504        256         24           82.0           16.0  \n",
       "87506         23          1          788.0        22525.0  \n",
       "87508        104          5           24.0         1819.0  \n",
       "87509         31          1          550.0        15303.0  \n",
       "\n",
       "[87510 rows x 17 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = ENGLISH_STOP_WORDS.union(['disneyland','tokyo','disney', 'im', 'tdrnow','paris','california','amp','disneysea','got',\n",
    "                                         'ºc', 'ºf', 'ºoº','𝗧𝗵𝗲','くまのプーさん', 'ディズニー', 'ディズニーシー','ディズニーハロウィーン',\n",
    "                                         'ディズニーランド', 'ディズニー好きと繋がりたい', 'フェスティバルオブミスティーク', 'マルマン',\n",
    "                                         'ㅋㅋㅋ', '場所', '更新', '月released', '東京ディズニーシー', '東京ディズニーランド', '東京ディズニーリゾート',\n",
    "                                         '香港迪士尼樂園', 'ºº', 'hong', 'kong',\"disneylandresort\", \"disneyland\", \"disneyresort\",\n",
    "                                          \"californiaadventure\",'downtowndisney','disneyanaheim','disneylandanaheim',\n",
    "                                          'disneycalifornia','californiadisney','disneysea', 'disneytokyo', 'disneytokyoresort', \n",
    "                                          'tokyodisney','tokyodisneyresort', 'tokyodisneyland','東京ディズニーランド', 'ディズニーランド',\n",
    "                                          '東京ディズニーシー', 'ズニーシー', 'tdr_now', 'tdr_md','tdr','dca','dl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_count</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 229 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hash_count  emoji_count  anger  anticipation  disgust  fear  joy  sadness  \\\n",
       "0           1            0      0             0        0     0    0        0   \n",
       "1           0            0      0             0        1     1    0        2   \n",
       "2           1            0      0             1        0     0    0        0   \n",
       "3           8            0      0             0        0     0    0        0   \n",
       "4           2            0      0             0        0     0    0        0   \n",
       "\n",
       "   surprise  trust  ...  206  207  208  209  210  211  212  213  214  215  \n",
       "0         0      0  ...    0    0    1    0    0    0    0    0    0    0  \n",
       "1         0      0  ...    0    0    0    0    0    0    0    0    1    0  \n",
       "2         0      0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "3         0      0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "4         0      0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 229 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['label']\n",
    "# TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(stop_words = my_stop_words, min_df = 0.005)\n",
    "X_tfidf = tfidf_vect.fit_transform(df['clean_text'])\n",
    "X_tfidf_feat = pd.concat([df[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']], pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "\n",
    "# CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words = my_stop_words, min_df = 0.005)\n",
    "X_count = count_vect.fit_transform(df['clean_text'])\n",
    "X_count_feat = pd.concat([df[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']], pd.DataFrame(X_count.toarray())], axis=1)\n",
    "\n",
    "X_count_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale data\n",
    "from sklearn import preprocessing\n",
    "X_count_scaled = preprocessing.scale(X_count_feat)\n",
    "X_tfidf_scaled = preprocessing.scale(X_tfidf_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 29504), (1, 29504), (2, 29504), (3, 29504), (4, 29504), (5, 29504)]\n"
     ]
    }
   ],
   "source": [
    "#Balance train Data \n",
    "ros = RandomOverSampler(random_state=77)\n",
    "X_ros_count, y_ros = ros.fit_resample(X_count_scaled, y)\n",
    "X_ros_tfidf, y_ros = ros.fit_resample(X_tfidf_scaled, y)\n",
    "print(sorted(Counter(y_ros).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 29504), (1, 29504), (2, 29504), (3, 29504), (4, 29504), (5, 29504)]\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=77)\n",
    "X_count_r, y_r = ros.fit_resample(X_count_feat, y)\n",
    "X_tfidf_r, y_r = ros.fit_resample(X_tfidf_feat, y)\n",
    "print(sorted(Counter(y_r).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'newton-cg', multi_class = 'multinomial')\n",
    "cv_lr_count = cross_val_score(lr, X_ros_count, y_ros, cv = 5)\n",
    "cv_lr_tfidf = cross_val_score(lr, X_ros_tfidf, y_ros, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 Fold CV: [0.59336076 0.6011313  0.58513313 0.59793166 0.58661867] \n",
      " \n",
      " Mean:0.592835104559479 \n",
      " \n",
      "\n",
      " 5 Fold CV: [0.59353217 0.59701748 0.58164781 0.59410353 0.58221917] \n",
      " \n",
      " Mean:0.5897040338247057 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f' 5 Fold CV: {cv_lr_count} \\n \\n Mean:{cv_lr_count.mean()} \\n \\n')\n",
    "print(f' 5 Fold CV: {cv_lr_tfidf} \\n \\n Mean:{cv_lr_tfidf.mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 401 ms, total: 1min 16s\n",
      "Wall time: 1h 4min 47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(multi_class = 'multinomial')\n",
    "\n",
    "#Hyper tuning\n",
    "max_iter = [100, 300, 500]\n",
    "solver = ['newton-cg', 'sag', 'saga']\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(max_iter=max_iter, solver = solver, C=C)\n",
    "\n",
    "clf = RandomizedSearchCV(lr, hyperparameters, cv=5, n_jobs=-1, \n",
    "                         n_iter = 10, random_state = 77)\n",
    "%time lr_cv_fit = clf.fit(X_ros_count, y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'sag', 'max_iter': 100, 'C': 3593.813663804626}\n"
     ]
    }
   ],
   "source": [
    "print(lr_cv_fit.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=3593.813663804626, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
       "                   penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49128366775126536"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_fit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 49s, sys: 3.4 s, total: 12min 52s\n",
      "Wall time: 40min 29s\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(multi_class = 'multinomial')\n",
    "\n",
    "#Hyper tuning \n",
    "max_iter = [100, 300, 500]\n",
    "\n",
    "solver = ['newton-cg', 'sag', 'saga']\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C = C, max_iter = max_iter, solver = solver)\n",
    "\n",
    "clf = RandomizedSearchCV(lr, hyperparameters, cv=5, n_jobs=-1, \n",
    "                         n_iter = 10, random_state = 77)\n",
    "%time lr_cv_fit_t = clf.fit(X_ros_tfidf, y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'newton-cg', 'max_iter': 100, 'C': 21.544346900318832}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_fit_t.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=21.544346900318832, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
       "                   penalty='l2', random_state=None, solver='newton-cg',\n",
       "                   tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_fit_t.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48837445770065074"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_fit_t.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multinomial Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.9 s, sys: 35.8 s, total: 1min 8s\n",
      "Wall time: 13min 46s\n"
     ]
    }
   ],
   "source": [
    "nb_clf = MultinomialNB()\n",
    "\n",
    "alpha = np.linspace(0.05,1,1000)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(alpha = alpha)\n",
    "\n",
    "clf = GridSearchCV(nb_clf, hyperparameters, cv=5, n_jobs=-1)\n",
    "%time nb_cv_fit = clf.fit(X_count_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.05}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cv_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.05, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cv_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.458960366955893"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cv_fit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32 s, sys: 41.6 s, total: 1min 13s\n",
      "Wall time: 12min 6s\n"
     ]
    }
   ],
   "source": [
    "nb_clf = MultinomialNB()\n",
    "\n",
    "alpha = np.linspace(0.05,1,1000)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(alpha = alpha)\n",
    "\n",
    "clf = GridSearchCV(nb_clf, hyperparameters, cv=5, n_jobs=-1)\n",
    "%time nb_cv_fit_t = clf.fit(X_tfidf_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.08993993993993994}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cv_fit_t.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.08993993993993994, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cv_fit_t.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46316883586406365"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cv_fit_t.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 47s, sys: 2.41 s, total: 5min 49s\n",
      "Wall time: 2h 12min 1s\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier Countvectorizer\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_estimators': range(50,1000,100), \n",
    "    'max_depth': [5,500,50],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(rf_clf, hyperparameters, cv=5, n_jobs=-1, \n",
    "                         n_iter = 10, random_state = 77)\n",
    "%time rf_cv_fit = clf.fit(X_count_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 250, 'max_features': 'log2', 'max_depth': 500}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=500, max_features='log2', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=250,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.876547812725958"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_fit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 22s, sys: 2.59 s, total: 6min 24s\n",
      "Wall time: 2h 21min 35s\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier TFIDF\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_estimators': range(50,1000,100), \n",
    "    'max_depth': [5,500,50],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(rf_clf, hyperparameters, cv=5, n_jobs=-1, \n",
    "                         n_iter = 10, random_state = 77)\n",
    "%time rf_cv_fit_t = clf.fit(X_tfidf_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 250, 'max_features': 'log2', 'max_depth': 500}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_fit_t.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=500, max_features='log2', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=250,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_fit_t.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8776324114244396"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_fit_t.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBooostClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 2min 27s, sys: 2.51 s, total: 2h 2min 30s\n",
      "Wall time: 6h 6min 18s\n"
     ]
    }
   ],
   "source": [
    "#Instantiate our model \n",
    "xg_clf = xgb.XGBClassifier()\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250], \n",
    "    'max_depth': [5, 7, 11, 15],\n",
    "    'learning_rate': [0.1,0.3,0.5,0.7,0.9,1],\n",
    "    'alpha': [5,10,15,20]\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(xg_clf, hyperparameters, cv=5, n_jobs=-1, \n",
    "                         n_iter = 10, random_state = 77)\n",
    "%time xg_cv_fit = clf.fit(X_count_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 250, 'max_depth': 15, 'learning_rate': 0.7, 'alpha': 20}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cv_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=20, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.7, max_delta_step=0, max_depth=15,\n",
       "              min_child_weight=1, missing=None, n_estimators=250, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cv_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8602223427331888"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cv_fit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 3min 7s, sys: 2.48 s, total: 2h 3min 10s\n",
      "Wall time: 5h 58min 59s\n"
     ]
    }
   ],
   "source": [
    "#Instantiate our model \n",
    "xg_clf = xgb.XGBClassifier()\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250], \n",
    "    'max_depth': [5, 7, 11, 15],\n",
    "    'learning_rate': [0.1,0.3,0.5,0.7,0.9,1],\n",
    "    'alpha': [5,10,15,20]\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(xg_clf, hyperparameters, cv=5, n_jobs=-1, \n",
    "                         n_iter = 10, random_state = 77)\n",
    "%time xg_cv_fit_t = clf.fit(X_tfidf_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 250, 'max_depth': 15, 'learning_rate': 0.7, 'alpha': 20}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cv_fit_t.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=20, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.7, max_delta_step=0, max_depth=15,\n",
       "              min_child_weight=1, missing=None, n_estimators=250, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cv_fit_t.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8545169016630514"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cv_fit_t.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K Nearest Neighbor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 476 ms, sys: 790 ms, total: 1.27 s\n",
      "Wall time: 23min 17s\n"
     ]
    }
   ],
   "source": [
    "#KNN CountVectorizer\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_neighbors': range(5,50,10), \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(knn, hyperparameters, cv=5, n_jobs=-1, \n",
    "                         n_iter = 10, random_state = 77)\n",
    "%time knn_cv_fit = clf.fit(X_count_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': 'distance', 'n_neighbors': 15, 'algorithm': 'brute'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=15, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7214276030368764"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_fit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 628 ms, sys: 995 ms, total: 1.62 s\n",
      "Wall time: 21min 13s\n"
     ]
    }
   ],
   "source": [
    "#KNN TFIDF \n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_neighbors': range(5,50,10), \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(knn, hyperparameters, cv=5, n_jobs=-1, \n",
    "                         n_iter = 10, random_state = 77)\n",
    "%time knn_cv_fit_t = clf.fit(X_tfidf_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': 'distance', 'n_neighbors': 15, 'algorithm': 'brute'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_fit_t.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=15, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_fit_t.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7181455621836587"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_fit_t.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing the Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['hash_count', 'emoji_count','clean_text',\n",
    "                                                        'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']], df['label'],test_size =0.20, random_state = 77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count vectorizer Document term matrix\n",
    "\n",
    "count_vecto = CountVectorizer(stop_words = my_stop_words, min_df = 0.005)\n",
    "count_vecto_fit = count_vecto.fit(X_train['clean_text'])\n",
    "\n",
    "count_train = count_vecto_fit.transform(X_train['clean_text'])\n",
    "count_test = count_vecto_fit.transform(X_test['clean_text'])\n",
    "\n",
    "X_train_vect = pd.concat([X_train[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(count_train.toarray())], axis=1)\n",
    "X_test_vect = pd.concat([X_test[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(count_test.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70008, 230)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 23522), (1, 23522), (2, 23522), (3, 23522), (4, 23522), (5, 23522)]\n"
     ]
    }
   ],
   "source": [
    "#Balance train Data \n",
    "ros = RandomOverSampler(random_state=77)\n",
    "X_resampled_ros, y_resampled_ros = ros.fit_resample(X_train_vect.values, y_train.values)\n",
    "print(sorted(Counter(y_resampled_ros).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5982), (1, 5982), (2, 5982), (3, 5982), (4, 5982), (5, 5982)]\n"
     ]
    }
   ],
   "source": [
    "#Balance test data\n",
    "X_resampled_ros_test, y_resampled_ros_test = ros.fit_resample(X_test_vect.values, y_test.values)\n",
    "print(sorted(Counter(y_resampled_ros_test).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 5855.502 / Predict time: 7.546 ---- Precision: 0.618 / Recall: 0.59 / Accuracy: 0.59\n"
     ]
    }
   ],
   "source": [
    "#Xgboost \n",
    "\n",
    "#{'n_estimators': 250, 'max_depth': 15, 'learning_rate': 0.7, 'alpha': 20}\n",
    "\n",
    "\n",
    "#Instantiate our model \n",
    "xg_clf = xgb.XGBClassifier(learning_rate = 0.7,\n",
    "                max_depth = 15, alpha = 20, n_estimators = 250)\n",
    "\n",
    "\n",
    "#Model Fit \n",
    "start = time.time()\n",
    "xg_clf.fit(X_resampled_ros, y_resampled_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = xg_clf.predict(X_resampled_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>f11</td>\n",
       "      <td>86119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>f12</td>\n",
       "      <td>46782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>f10</td>\n",
       "      <td>37863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f0</td>\n",
       "      <td>12931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>f1</td>\n",
       "      <td>12777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>f3</td>\n",
       "      <td>8906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>f9</td>\n",
       "      <td>7148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>f6</td>\n",
       "      <td>5669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>f5</td>\n",
       "      <td>5457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>f7</td>\n",
       "      <td>4581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>f8</td>\n",
       "      <td>4427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>f2</td>\n",
       "      <td>4427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>f4</td>\n",
       "      <td>3278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>f210</td>\n",
       "      <td>1679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>f77</td>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>f44</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>f194</td>\n",
       "      <td>1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>f82</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>f103</td>\n",
       "      <td>1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>f195</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "10      f11       86119\n",
       "6       f12       46782\n",
       "4       f10       37863\n",
       "3        f0       12931\n",
       "15       f1       12777\n",
       "22       f3        8906\n",
       "67       f9        7148\n",
       "20       f6        5669\n",
       "0        f5        5457\n",
       "1        f7        4581\n",
       "23       f8        4427\n",
       "19       f2        4427\n",
       "11       f4        3278\n",
       "17     f210        1679\n",
       "43      f77        1433\n",
       "40      f44        1406\n",
       "82     f194        1380\n",
       "107     f82        1218\n",
       "64     f103        1156\n",
       "94     f195         850"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_fea_imp = pd.DataFrame(xg_clf.get_booster().get_fscore().items(),columns=['feature','importance']).sort_values('importance', ascending=False)\n",
    "xgb_fea_imp[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 27.188 / Predict time: 0.732 ---- Precision: 0.63 / Recall: 0.596 / Accuracy: 0.596\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "#{'n_estimators': 250, 'max_features': 'log2', 'max_depth': 500}\n",
    "\n",
    "\n",
    "#Instantiate our model \n",
    "rf = RandomForestClassifier(n_estimators = 250, max_depth = 500, max_features = 'log2',\n",
    "                            n_jobs=-1)\n",
    "\n",
    "#Model Fit \n",
    "start = time.time()\n",
    "rf.fit(X_resampled_ros, y_resampled_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_resampled_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.12870380391849415, 'tweet_len'),\n",
       " (0.07867563171545214, 'cap_count'),\n",
       " (0.07063985959616721, 'punc_count'),\n",
       " (0.05441362132758469, 'hash_count'),\n",
       " (0.028060034877217623, 'sadness'),\n",
       " (0.026234639341441757, 'emoji_count'),\n",
       " (0.024265398872350682, 'joy'),\n",
       " (0.024125873865076173, 'fear'),\n",
       " (0.01916960208726278, 'anticipation'),\n",
       " (0.01807146593302367, 'anger'),\n",
       " (0.01756454389351802, 'trust'),\n",
       " (0.015189076780071465, 'disgust'),\n",
       " (0.012374833514527287, 'surprise'),\n",
       " (0.011428051480100393, 29),\n",
       " (0.010688031921792449, 90),\n",
       " (0.0073147790903301075, 197),\n",
       " (0.00715028248076272, 31),\n",
       " (0.005981077915899386, 69),\n",
       " (0.005931986299466755, 181),\n",
       " (0.00583769231558105, 64)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "(sorted(zip(importances, X_train_vect.columns), reverse=True))[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 0.111 / Predict time: 0.018 ---- Precision: 0.518 / Recall: 0.514 / Accuracy: 0.514\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Bayes\n",
    "\n",
    "#Instantiate our model \n",
    "nb_clf = MultinomialNB(alpha = 0.05)\n",
    "\n",
    "#Train our Model \n",
    "start = time.time()\n",
    "nb_clf.fit(X_resampled_ros, y_resampled_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = nb_clf.predict(X_resampled_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), \n",
    "    round(recall, 3), round((y_pred==y_resampled_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logitstic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale data\n",
    "from sklearn import preprocessing\n",
    "X_train_scaled = preprocessing.scale(X_resampled_ros)\n",
    "X_test_scaled = preprocessing.scale(X_resampled_ros_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 63.143 / Predict time: 0.006 ---- Precision: 0.601 / Recall: 0.586 / Accuracy: 0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "\n",
    "#Instantiate our model\n",
    "lr = LogisticRegression(max_iter = 100, solver = 'sag', multi_class = 'multinomial', \n",
    "                        C = 3593.81)\n",
    "\n",
    "#Train our Model\n",
    "start = time.time()\n",
    "lr.fit(X_train_scaled, y_resampled_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), \n",
    "    round((y_pred==y_resampled_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 0.007 / Predict time: 91.01 ---- Precision: 0.375 / Recall: 0.372 / Accuracy: 0.372\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Instantiate our model \n",
    "knn = KNeighborsClassifier(n_neighbors = 15, weights = 'distance', algorithm = 'brute')\n",
    "\n",
    "#Model Fit \n",
    "start = time.time()\n",
    "knn.fit(X_resampled_ros, y_resampled_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = knn.predict(X_resampled_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF vectorizer Document term matrix\n",
    "\n",
    "tfidf_vecto = TfidfVectorizer(stop_words = my_stop_words, min_df = 0.005)\n",
    "tfidf_vecto_fit = tfidf_vecto.fit(X_train['clean_text'])\n",
    "\n",
    "tfidf_train = tfidf_vecto_fit.transform(X_train['clean_text'])\n",
    "tfidf_test = tfidf_vecto_fit.transform(X_test['clean_text'])\n",
    "\n",
    "X_train_t_vect = pd.concat([X_train[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "X_test_t_vect = pd.concat([X_test[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_test.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 23522), (1, 23522), (2, 23522), (3, 23522), (4, 23522), (5, 23522)]\n"
     ]
    }
   ],
   "source": [
    "#Balance train Data \n",
    "ros = RandomOverSampler(random_state=77)\n",
    "X_tfidf_ros, y_tfidf_ros = ros.fit_resample(X_train_t_vect.values, y_train.values)\n",
    "print(sorted(Counter(y_tfidf_ros).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5982), (1, 5982), (2, 5982), (3, 5982), (4, 5982), (5, 5982)]\n"
     ]
    }
   ],
   "source": [
    "#Balance test data\n",
    "X_tfidf_ros_test, y_tfidf_ros_test = ros.fit_resample(X_test_vect.values, y_test.values)\n",
    "print(sorted(Counter(y_tfidf_ros_test).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 5972.105 / Predict time: 6.773 ---- Precision: 0.573 / Recall: 0.531 / Accuracy: 0.531\n"
     ]
    }
   ],
   "source": [
    "#Xgboost \n",
    "\n",
    "#{'n_estimators': 250, 'max_depth': 15, 'learning_rate': 0.7, 'alpha': 20}\n",
    "\n",
    "\n",
    "#Instantiate our model \n",
    "xg_clf = xgb.XGBClassifier(learning_rate = 0.7,\n",
    "                max_depth = 15, alpha = 20, n_estimators = 250)\n",
    "\n",
    "\n",
    "#Model Fit \n",
    "start = time.time()\n",
    "xg_clf.fit(X_tfidf_ros, y_tfidf_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = xg_clf.predict(X_tfidf_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_tfidf_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_tfidf_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_fea_imp = pd.DataFrame(xg_clf.get_booster().get_fscore().items(),columns=['feature','importance']).sort_values('importance', ascending=False)\n",
    "xgb_fea_imp[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 28.714 / Predict time: 0.732 ---- Precision: 0.622 / Recall: 0.587 / Accuracy: 0.587\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "#{'n_estimators': 250, 'max_features': 'log2', 'max_depth': 500}\n",
    "\n",
    "\n",
    "#Instantiate our model \n",
    "rf = RandomForestClassifier(n_estimators = 250, max_depth = 500, max_features = 'log2',\n",
    "                            n_jobs=-1)\n",
    "\n",
    "#Model Fit \n",
    "start = time.time()\n",
    "rf.fit(X_tfidf_ros, y_tfidf_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_tfidf_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_tfidf_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_tfidf_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 0.069 / Predict time: 0.019 ---- Precision: 0.521 / Recall: 0.518 / Accuracy: 0.518\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Bayes\n",
    "\n",
    "#Instantiate our model \n",
    "nb_clf = MultinomialNB(alpha = 0.0899399)\n",
    "\n",
    "#Train our Model \n",
    "start = time.time()\n",
    "nb_clf.fit(X_tfidf_ros, y_tfidf_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = nb_clf.predict(X_tfidf_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_tfidf_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), \n",
    "    round(recall, 3), round((y_pred==y_tfidf_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 0.036 / Predict time: 90.02 ---- Precision: 0.387 / Recall: 0.386 / Accuracy: 0.386\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Instantiate our model \n",
    "knn = KNeighborsClassifier(n_neighbors = 15, weights = 'distance', algorithm = 'brute')\n",
    "\n",
    "#Model Fit \n",
    "start = time.time()\n",
    "knn.fit(X_tfidf_ros, y_tfidf_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = knn.predict(X_tfidf_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_tfidf_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_tfidf_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale data\n",
    "from sklearn import preprocessing\n",
    "X_train_scaled_t = preprocessing.scale(X_tfidf_ros)\n",
    "X_test_scaled_t = preprocessing.scale(X_tfidf_ros_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 61.095 / Predict time: 0.008 ---- Precision: 0.598 / Recall: 0.581 / Accuracy: 0.581\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "\n",
    "#Instantiate our model\n",
    "lr = LogisticRegression(max_iter = 100, solver = 'newton-cg', multi_class = 'multinomial', \n",
    "                        C = 21.5443469)\n",
    "\n",
    "#Train our Model\n",
    "start = time.time()\n",
    "lr.fit(X_train_scaled_t, y_tfidf_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = lr.predict(X_test_scaled_t)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_tfidf_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), \n",
    "    round((y_pred==y_tfidf_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Countvectorizer document matrix with Random Forest Classifier produced the best model. We will test it out with Naive Bayes and Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
